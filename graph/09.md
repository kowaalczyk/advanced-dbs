# Postgres vs neo4j

Aby porównać efektywność obliczenia spójnych składowych, postanowiłem zacząć od przeniesienia danych do neo4j.
Schemat który zaprojektowałem różni się od używanego w Postgresie tym, że relacje Author i Editor w neo4j
zamodelowałem jako krawędzie (w przypadku autora z parametrami), szczegóły są na załączonym pliku `graph_model.svg`.

Modelowanie i przenoszenie danych było koncepcyjnie proste, w moim przypadku proces konwersji 
danych które wcześniej ładowałem do Postresa z plików csv wyglądał następująco:

1. Skrypt `headers.py` wydziela z pliku csv nagłówek z nazwami kolumn i konwertuje je do formatu neo4j
2. Skrypt `load.sh` ładuje pliki csv ze wskazanego folderu do bazy, przy okazji czyszcząc zduplikowane relacje

Samo ładowanie okazało się bardziej problematyczne: okazało się że skrypt do ładowania danych z csv nie jest częścią
klienta (cli) bazy tak jak w przypadku postgresa - dla neo4j jest to część cli admina bazy, i pozwala wyłacznie na
czytanie plików z tego samego hosta na którym znajduje się baza. Ponieważ używałem neo4j w Dockerze, aby nie instalować
bazy lokalnie, wymagało to sporo zmian w konfiguracji i przesyłania danych przez docker volume 
(używałem to tego `minio` jako object storage, stąd dodatkowy kontener w pliku `docker-compose.yml`).

Po uporaniu się z technicznymi problemami, samo łądowanie przebiegało bardzo szybko, 
statystyki wkleiłem do pliku `import-stats.log`, a fragment otrzymanego grafu można zobaczyć w `graph.png`


## Zapytanie w neo4j

Początkowo rozważałem 2 strategie zapytania o spójne składowe:

1. Użycie rozszerzenia `graph-algorithms`, konkretnie funkcji `algo.unionFind`
2. Napisanie własnego zapytania

### Strategia unionFind

Instalacja rozszerzenia okazała się prosta i bezproblemowa, samo zapytanie wyglądało następująco:
```cypher
call algo.unionFind('Person', 'authored', {write: true, writeProperty: 'authoredComponentId'}) 
yield setCount, loadMillis, computeMillis, writeMillis;
```
Niestety jednak wykonanie go lokalnie wymagało zbyt dużo pamięci RAM, zdecydowałem się więc przenieść na mocniejszą 
maszynę (po ostatnich doświadczeniach ze students wynająłem serwer na digitalocean: 8 CPU, 32GB RAM, 100GB SSD).
Muszę przyznać, że nie spodziewałem się takiego obrotu wydarzeń, szczególnie że wbudowany w rozszerzenie algorytm
obliczania oczekiwanego zużycia pamięci nie był wysoki:
```cypher
call algo.unionFind.memrec('Person', 'authored', {write: true, writeProperty: 'authoredComponentId'}) 
yield requiredMemory;
```
> [116 MiB ... 284 MiB]

Na nowej maszynie udało się odpalić zapytanie, które wykonało się zaskakująco szybko:
> Started streaming 1 records after 9531 ms and completed after 9531 ms.

Niestety zapytanie nie przyniosło zamierzonych efektów:
każdy z wierzchołków był przypisany tylko do siebie samego (każda składowa miała wielkość 1)

Myśląc że to mój błąd, zacząłem eksperymentować z argumentami. Próbowałem odpalić algorytm
bez filtrowania wg. wierzchołków (aby wykrywać wierzchołki typu `Person` ale też `Publication`, przez które
przechodzi relacja współautorstwa):
```cypher
call algo.unionFind(null, 'edited', {write: true, writeProperty: 'editedComponentId'}) 
yield setCount, loadMillis, computeMillis, writeMillis;
```

Dokładna treść zapytania znajduje się w pliku `set-coauthors.cypher`, a treść zapytania za pomocą którego 
liczyłem wielkość składowych jest w `get-coauthors.cypher`.
Wyniki zapytania, które niestety są błędne (tak samo jak w pierwszym przypadku) znajdują się w pliku `coauthors.csv`.

Okazało się, że nie jestem w stanie nawet zreprodukować przykładu wykorzystania `unionFind` z oficjalnej dokumentacji,
także podejrzewam że jest to błąd w samej implementacji algorytmu. 
Szczegóły opisałem w [issue na GitHubie](https://github.com/neo4j-contrib/neo4j-graph-algorithms/issues/920).


### Własne zapytanie

Po całym dniu spędzonym na walce z wbudowanymi algorytmami neo4j, postanowiłem napisać własne zapytanie.
Zacząłem od skonstruowania powiązań bezpośrednio między współautorami, za pomocą następującego zapytania.
```cypher
match (p1:Person)-[:authored]->(p:Publication)<-[:authored]-(p2:Person) 
where id(p1) < id (p2) 
merge (p1)-[:is_coauthor]->(p2) 
return count(p);
```
> There is not enough memory to perform the current task. Please try increasing 'dbms.memory.heap.max_size' in the neo4j 
> configuration (normally in 'conf/neo4j.conf' or, if you you are using Neo4j Desktop, found through the user interface)
> or if you are running an embedded installation increase the heap by using '-Xmx' command line flag, and then restart 
> the database.

Niestety jak widać nawet 32GB RAM nie wystarcza aby zbudować taką listę (konkretne ustawienia neo4j których używałem
są w pliku `conf/neo4j.conf`, ograniczenia pamięci zostały ustawione zgodnie z instrukcjami twórców bazy).
Próbowałem powtórzyć zapytanie kilka razy ze zmienionymi ustawieniami, zawsze jednak kończyło się ono błędami pamięci
lub brakiem wyniku po godzinie oczekiwania.
Biorąc pod uwagę że Postgres nie miał z tym problemu (nawet na laptopie z 2x mniejszą pamięcią), 
można przypuszczać że neo4j próbuje robić zdecydowanie więcej w pamięci RAM niż na dysku.

Plan tego zapytania znajduje się w załączonym pliku `plan.png`, jednak ciężko było mi stwierdzić
co konkretnie powoduje takie zapełnienie pamięci. Zanim jednak zapytanie zapcha całą pamięć,
wykonuje się ono przez co najmniej 40 min - znacznie dłużej niż 6-7 min w przypadku Postgresa. 
Jest to zapewne w dużej mierze spowodowane faktem, że w neo4j `merge` jest wykonywany
dla każdego wiersza (których w tym przypadku jest kwadratowo wiele).

Prawdopodobnie aby pozbyć się tego problemu, musiałbym użyć tabeli wygenerowanej w postgresie,
importując ją jako relację podobnie jak `Author` i `Editor`. Niestety jednak zabrakło mi czasu
aby sprawdzić to podejście.

## Podsumowanie

Po ponad 2 dniach eksperymentów z neo4j nie jestem w stanie stworzyć zapytania które działałoby zgodnie z oczeikwaniami.
Dla przypomnienia, analogiczne zapytanie z postgresa wyglądało tak:
```sql
create materialized view coauthor_graph as
    with coauthors as (
        select  a1.person_id as author1_id,
                a2.person_id as author2_id,
                a1.publication_key as publication_key
        from author a1
        left join author a2
        -- setting order on a join to represent each edge exactly once
        on a1.person_id < a2.person_id and a1.publication_key = a2.publication_key
        where a2.person_id is not null
    ),  publication_weight as (
        select  min(publication_key) as publication_key,
                (cast(1 as float8) / count(person_id)) as publ_weight
        from author
        group by publication_key
    ),  edge_weights as (
        select  min(author1_id) as author1_id,
                min(author2_id) as author2_id,
                count(coauthors.publication_key) as pair_count,
                sum(publ_weight) as pair_weight
        from coauthors
        left join publication_weight
        on coauthors.publication_key = publication_weight.publication_key
        group by author1_id, author2_id
    ) select * from edge_weights;
```
i jego czas wykonania na moim laptopie wynosił 6 m 13 s 105 ms.

Czy to świadczy o wyższości Postgresa nad neo4j? Raczej nie.

Przez ostatnie kilka dni dowiedziałem się wiele nt grafowych baz danych, jednak
nie wystarczająco wiele aby mieć pewność że zrobiłem wszystko co mogę aby zoptymalizować zapytanie.
Oprócz tego, intuicja podpowiada mi że gdybym znalazł czas na wgranie całej relacji współautorstwa
wygenerowanej w postgresie do neo4j, to druga część zapytania (o wielkość spójnych składowych) byłaby
znacznie efektywniejsze w neo4j (w postgresie moje zapytanie nie było w stanie się wykonać na laptopie ani
na students, nie miałem czasu aby wykonać eksperymentu na nowej maszynie której używam do neo4j).

Konkretne kroki które chciałbym wykonać w przyszłości to:
1. test zapytania w postgresie na nowej maszynie
2. eksport widoku współautorów (krawędzi autor-autor) z postgresa do neo4j
3. zmierzenie czasów zapytań w obu bazach i dalsza optymalizacja
